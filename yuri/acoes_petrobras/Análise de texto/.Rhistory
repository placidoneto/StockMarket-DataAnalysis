source("traducao_pct_sentimentos.R")
install.packages("tidyverse", dependencies = T)
#
# require(streamR)
# require(tidytext)
# library(dplyr)
# library(stringr)
# require(ggplot2)
require(tidyverse)
tts <-  parseTweets("acoes_petrobras_dados.json", simplify = T)
texto <- tts$text
# texto <- as.list(texto)
pont <- gsub(pattern = "[[:punct:]]","",texto)
con <- gsub(pattern = "[[:cntrl:]]","",pont)
low <- tolower(con)
dig <- gsub(pattern = "[[:digit:]]","",low)
tokenizar <- str_split(dig,"[[:space:]]")
words <- unlist(tokenizar)
words_df <- as.data.frame(words)
names(words_df) <- "palavras"
nova_df <-  semi_join(words_df,col_palavras_traduzida, by = "palavras")
nova_df$sentimento
# positivo <- filter(nova_df, sentimento == "positive")
# negativo <- filter(nova_df, sentimento == "negative")
# neutro <- filter(nova_df, sentimento == "both")
setwd("R/R_scripts/acoes_petrobras/")
source("traducao_pct_sentimentos.R")
setwd("AnÃ¡lise de texto/")
source("traducao_pct_sentimentos.R")
tts <-  parseTweets("acoes_petrobras_dados.json", simplify = T)
texto <- tts$text
# texto <- as.list(texto)
pont <- gsub(pattern = "[[:punct:]]","",texto)
con <- gsub(pattern = "[[:cntrl:]]","",pont)
low <- tolower(con)
dig <- gsub(pattern = "[[:digit:]]","",low)
tokenizar <- str_split(dig,"[[:space:]]")
words <- unlist(tokenizar)
words_df <- as.data.frame(words)
names(words_df) <- "palavras"
nova_df <-  semi_join(words_df,col_palavras_traduzida, by = "palavras")
nova_df$sentimento
tts <-  parseTweets("acoes_petrobras_dados.json", simplify = T)
texto <- tts$text
require(streamR)
# require(tidytext)
# library(dplyr)
# library(stringr)
# require(ggplot2)
require(tidyverse)
tts <-  parseTweets("acoes_petrobras_dados.json", simplify = T)
texto <- tts$text
# texto <- as.list(texto)
pont <- gsub(pattern = "[[:punct:]]","",texto)
con <- gsub(pattern = "[[:cntrl:]]","",pont)
low <- tolower(con)
dig <- gsub(pattern = "[[:digit:]]","",low)
tokenizar <- str_split(dig,"[[:space:]]")
words <- unlist(tokenizar)
words_df <- as.data.frame(words)
names(words_df) <- "palavras"
nova_df <-  semi_join(words_df,col_palavras_traduzida, by = "palavras")
nova_df$sentimento
tts <-  parseTweets("acoes_petrobras_dados.json", simplify = T)
texto <- tts$text
pont <- gsub(pattern = "[[:punct:]]","",texto)
con <- gsub(pattern = "[[:cntrl:]]","",pont)
low <- tolower(con)
dig <- gsub(pattern = "[[:digit:]]","",low)
tokenizar <- str_split(dig,"[[:space:]]")
words <- unlist(tokenizar)
source("traducao_pct_sentimentos.R")
install.packages("tidyverse", dependencies = T)
#
require(streamR)
# require(tidytext)
library(dplyr)
library(stringr)
require(ggplot2)
require(tidyverse)
tts <-  parseTweets("acoes_petrobras_dados.json", simplify = T)
texto <- tts$text
# texto <- as.list(texto)
pont <- gsub(pattern = "[[:punct:]]","",texto)
con <- gsub(pattern = "[[:cntrl:]]","",pont)
low <- tolower(con)
dig <- gsub(pattern = "[[:digit:]]","",low)
tokenizar <- str_split(dig,"[[:space:]]")
words <- unlist(tokenizar)
words_df <- as.data.frame(words)
names(words_df) <- "palavras"
nova_df <-  semi_join(words_df,col_palavras_traduzida, by = "palavras")
nova_df$sentimento
# positivo <- filter(nova_df, sentimento == "positive")
# negativo <- filter(nova_df, sentimento == "negative")
# neutro <- filter(nova_df, sentimento == "both")
install.packages("tidyverse", dependencies = T)
source("traducao_pct_sentimentos.R")
#install.packages("tidyverse", dependencies = T)
#
require(streamR)
# require(tidytext)
library(dplyr)
library(stringr)
require(ggplot2)
require(tidyverse)
tts <-  parseTweets("acoes_petrobras_dados.json", simplify = T)
texto <- tts$text
# texto <- as.list(texto)
pont <- gsub(pattern = "[[:punct:]]","",texto)
con <- gsub(pattern = "[[:cntrl:]]","",pont)
low <- tolower(con)
dig <- gsub(pattern = "[[:digit:]]","",low)
tokenizar <- str_split(dig,"[[:space:]]")
words <- unlist(tokenizar)
words_df <- as.data.frame(words)
names(words_df) <- "palavras"
nova_df <-  semi_join(words_df,col_palavras_traduzida, by = "palavras")
nova_df$sentimento
# positivo <- filter(nova_df, sentimento == "positive")
# negativo <- filter(nova_df, sentimento == "negative")
# neutro <- filter(nova_df, sentimento == "both")
View(nova_df)
names(nova_df)
nova_df <-  select(words_df, palavras) semi_join(words_df,col_palavras_traduzida, by = "palavras")
nova_df <-  select(words_df, palavras) %>% semi_join(words_df,col_palavras_traduzida, by = "palavras")
View(nova_df)
nova_df <-  select(col_palavras_traduzida, palavras) %>% semi_join(words_df,col_palavras_traduzida, by = "palavras")
nova_df <-  select(col_palavras_traduzida, palavras) %>%
semi_join(words_df,col_palavras_traduzida, by = "palavras")
View(nova_df)
names(col_palavras_traduzida)
nova_df <-  select(col_palavras_traduzida, sentimento) %>%
semi_join(words_df,col_palavras_traduzida, by = "palavras")
nova_df <-  select(col_palavras_traduzida, sentimento,palavras) %>%
semi_join(words_df,col_palavras_traduzida, by = "palavras")
View(nova_df)
tts <-  parseTweets("deCasa03.json", simplify = T)
texto <- tts$text
# texto <- as.list(texto)
pont <- gsub(pattern = "[[:punct:]]","",texto)
con <- gsub(pattern = "[[:cntrl:]]","",pont)
low <- tolower(con)
dig <- gsub(pattern = "[[:digit:]]","",low)
tokenizar <- str_split(dig,"[[:space:]]")
words <- unlist(tokenizar)
words_df <- as.data.frame(words)
names(words_df) <- "palavras"
nova_df <-  select(col_palavras_traduzida, sentimento,palavras) %>%
semi_join(words_df,col_palavras_traduzida, by = "palavras")
View(nova_df)
nova_df <-  select(col_palavras_traduzida, sentimento,palavras) %>%
semi_join(col_palavras_traduzida, words_df by = "palavras")
nova_df <-  select(col_palavras_traduzida, sentimento, palavras) %>%
semi_join(col_palavras_traduzida, words_df by = "palavras")
nova_df <-  select(col_palavras_traduzida, sentimento, palavras) %>%
semi_join(col_palavras_traduzida, words_df, by = "palavras")
View(nova_df)
tts <-  parseTweets("acoes_petrobras_dados.json", simplify = T)
texto <- tts$text
# texto <- as.list(texto)
pont <- gsub(pattern = "[[:punct:]]","",texto)
con <- gsub(pattern = "[[:cntrl:]]","",pont)
low <- tolower(con)
dig <- gsub(pattern = "[[:digit:]]","",low)
tokenizar <- str_split(dig,"[[:space:]]")
words <- unlist(tokenizar)
words_df <- as.data.frame(words)
names(words_df) <- "palavras"
nova_df <-  select(col_palavras_traduzida, sentimento, palavras) %>%
semi_join(col_palavras_traduzida, words_df, by = "palavras")
nova_df <-  select(col_palavras_traduzida, sentimento, palavras) %>%
semi_join(words_df, col_palavras_traduzida, by = "palavras")
tts <-  parseTweets("deCasa03.json", simplify = T)
texto <- tts$text
# texto <- as.list(texto)
pont <- gsub(pattern = "[[:punct:]]","",texto)
con <- gsub(pattern = "[[:cntrl:]]","",pont)
low <- tolower(con)
dig <- gsub(pattern = "[[:digit:]]","",low)
tokenizar <- str_split(dig,"[[:space:]]")
words <- unlist(tokenizar)
words_df <- as.data.frame(words)
names(words_df) <- "palavras"
nova_df <-  select(col_palavras_traduzida, sentimento, palavras) %>%
semi_join(words_df, col_palavras_traduzida, by = "palavras")
tts <-  parseTweets("deCasa00.json", simplify = T)
texto <- tts$text
# texto <- as.list(texto)
pont <- gsub(pattern = "[[:punct:]]","",texto)
con <- gsub(pattern = "[[:cntrl:]]","",pont)
low <- tolower(con)
dig <- gsub(pattern = "[[:digit:]]","",low)
tokenizar <- str_split(dig,"[[:space:]]")
words <- unlist(tokenizar)
words_df <- as.data.frame(words)
names(words_df) <- "palavras"
nova_df <-  select(col_palavras_traduzida, sentimento, palavras) %>%
semi_join(words_df, col_palavras_traduzida, by = "palavras")
View(nova_df)
nova_df <-  select(col_palavras_traduzida, sentimento) %>%
semi_join(words_df, col_palavras_traduzida, by = "palavras")
nova_df <-semi_join(words_df, col_palavras_traduzida, by = "palavras")%>%
select(col_palavras_traduzida, sentimento)
nova_df <-  select(col_palavras_traduzida, palavras) %>%
semi_join(words_df, col_palavras_traduzida, by = "palavras")
